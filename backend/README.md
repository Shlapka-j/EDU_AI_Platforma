# EDU AI Platform Backend

Backend server s **Ollama LLM** a **Vector Database** integrÃ¡ciou pre inteligentnÃ½ vzdÄ›lÃ¡vacÃ­ systÃ©m.

## ğŸš€ Funkcie

- **ğŸ¤– Ollama LLM Integration** - LokÃ¡lne AI modely (llama2, mxbai-embed-large)
- **ğŸ—„ï¸ Vector Database** - ChromaDB pre semantickÃ© vyhÄ¾adÃ¡vanie dokumentov
- **ğŸ“„ Document Processing** - PDF, DOCX, TXT embedding a indexovanie
- **ğŸ’¬ AI Chat** - Kontextovo-aware konverzÃ¡cie s prÃ­stupom k materiÃ¡lom
- **ğŸ” Semantic Search** - VyhÄ¾adÃ¡vanie relevantnÃ©ho obsahu v dokumentoch

## ğŸ“‹ PoÅ¾iadavky

### 1. Docker
```bash
# macOS
brew install docker

# Linux
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

### 2. Ollama
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh
```

## âš¡ RÃ½chla inÅ¡talÃ¡cia

```bash
# 1. Spustite setup script
./setup.sh

# 2. Spustite backend server
npm run dev
```

## ğŸ”§ ManuÃ¡lna inÅ¡talÃ¡cia

### 1. Spustite ChromaDB
```bash
docker run -d --name chromadb -p 8000:8000 chromadb/chroma
```

### 2. Spustite Ollama
```bash
ollama serve
```

### 3. Stiahnite AI modely
```bash
# LLM model pre chat (cca 4GB)
ollama pull llama2

# Embedding model pre vector search (cca 300MB)  
ollama pull mxbai-embed-large
```

### 4. Spustite backend
```bash
npm install
npm run dev
```

## ğŸŒ API Endpoints

| Endpoint | MetÃ³da | Popis |
|----------|--------|-------|
| `/api/health` | GET | Status sluÅ¾ieb |
| `/api/chat/message` | POST | AI chat konverzÃ¡cia |
| `/api/documents/upload` | POST | Nahranie a spracovanie dokumentu |
| `/api/documents/search` | GET | VyhÄ¾adÃ¡vanie v dokumentoch |
| `/api/documents/stats` | GET | Å tatistiky databÃ¡zy |

## ğŸ’¬ AI Chat API

```bash
curl -X POST http://localhost:3001/api/chat/message \\
  -H "Content-Type: application/json" \\
  -d '{
    "message": "Vysvetli mi gravitÃ¡ciu",
    "userRole": "student",
    "subject": "Fyzika"
  }'
```

## ğŸ“„ Document Upload API

```bash
curl -X POST http://localhost:3001/api/documents/upload \\
  -F "file=@uczebnica_fyziky.pdf" \\
  -F "subject=Fyzika" \\
  -F "grade=8"
```

## ğŸ” Search API

```bash
curl "http://localhost:3001/api/documents/search?query=gravitace&subject=Fyzika&limit=3"
```

## ğŸ—ï¸ ArchitektÃºra

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend API   â”‚    â”‚   Ollama LLM    â”‚
â”‚   React App     â”‚â”€â”€â”€â–¶â”‚   Express.js    â”‚â”€â”€â”€â–¶â”‚   Local Models  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   ChromaDB      â”‚
                       â”‚   Vector Store  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ KonfigurÃ¡cia

Upravte `.env` sÃºbor:

```env
# Server
PORT=3001
NODE_ENV=development

# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large

# ChromaDB
CHROMA_URL=http://localhost:8000

# Frontend
FRONTEND_URL=http://localhost:3000
```

## ğŸ“Š Monitoring

### Health Check
```bash
curl http://localhost:3001/api/health
```

### Document Stats  
```bash
curl http://localhost:3001/api/documents/stats
```

### Available Models
```bash
curl http://localhost:3001/api/chat/models
```

## ğŸ› Troubleshooting

### Ollama nereaguje
```bash
# Skontrolujte status
ollama list

# ReÅ¡tartujte service
ollama serve
```

### ChromaDB nedostupnÃ¡
```bash
# Skontrolujte container
docker ps | grep chroma

# ReÅ¡tartujte container
docker restart chromadb
```

### PomalÃ© AI odpovede
```bash
# PouÅ¾ite menÅ¡Ã­ model
ollama pull llama2:7b-chat

# Alebo phi3
ollama pull phi3:mini
```

## ğŸš€ Produkcia

Pre produkÄnÃ© nasadenie:

```bash
# Build backend
npm run build

# Spustite produkÄnÃ½ server
npm start
```

## ğŸ“ˆ Performance Tips

1. **GPU Acceleration** - Ollama automaticky vyuÅ¾ije GPU ak je dostupnÃ©
2. **Memory Management** - Nastavte `OLLAMA_NUM_PARALLEL=2` pre viac requestov
3. **Model Cache** - Modely sa cachujÃº po prvom pouÅ¾itÃ­
4. **Vector Index** - ChromaDB automaticky indexuje pre rÃ½chle vyhÄ¾adÃ¡vanie

## ğŸ” BezpeÄnosÅ¥

- VÅ¡etko beÅ¾Ã­ lokÃ¡lne - Å¾iadne dÃ¡ta sa neodosielajÃº na externÃ© servery
- Dokumenty sa spracovÃ¡vajÃº a ukladajÃº len lokÃ¡lne
- AI modely beÅ¾ia kompletne offline

## ğŸ“š DokumentÃ¡cia modelov

- **llama2** - Meta's LLM pre general chat
- **mxbai-embed-large** - Embedding model pre semantic search
- **phi3:mini** - MenÅ¡Ã­, rÃ½chlejÅ¡Ã­ model od Microsoft

---

**ğŸ“ EDU AI Platform** - LokÃ¡lne AI pre vzdelÃ¡vanie